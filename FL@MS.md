***
Back to https://github.com/Kwangkee/FL

## FL @ MicroSoft,  
Privacy Preserving Machine Learning Innovation, https://www.microsoft.com/en-us/research/group/privacy-preserving-machine-learning-innovation/   
Confidential AI, https://www.microsoft.com/en-us/research/project/confidential-ai/  
Privacy in AI (PAI), https://www.microsoft.com/en-us/research/group/privacy-in-ai/  
Differential Privacy: Project Laplace, https://www.microsoft.com/en-us/research/project/project-laplace/  
Project FTL, https://www.microsoft.com/en-us/research/project/project-flute/

***
## Privacy in AI (PAI)
- FLUTE: A Scalable, Extensible Framework for High-Performance Federated Learning Simulations, https://www.microsoft.com/en-us/research/publication/flute-a-scalable-extensible-framework-for-high-performance-federated-learning-simulations/ 
>In this paper we introduce “Federated Learning Utilities and Tools for Experimentation” (FLUTE), a high-performance open source platform for federated learning research and offline simulations. The goal of FLUTE is to enable rapid prototyping and simulation of new federated learning algorithms at scale, including novel optimization, privacy, and communications strategies. We describe the architecture of FLUTE, enabling arbitrary federated modeling schemes to be realized, we compare the platform with other state-of-the-art platforms, and we describe available features of FLUTE for experimentation in core areas of active research, such as optimization, privacy and scalability. We demonstrate the effectiveness of the platform with a series of experiments for text prediction and speech recognition, including the addition of differential privacy, quantization, scaling and a variety of optimization and federation approaches.

- Personalized Federated Learning with Adaptive Batchnorm for Healthcare, https://www.microsoft.com/en-us/research/publication/personalized-federated-learning-with-adaptive-batchnorm-for-healthcare/ 
>In this article, we propose FedAP to tackle domain shifts and then obtain personalized models for local clients. FedAP learns the similarity between clients based on the statistics of the batch normalization layers while preserving the specificity of each client with different local batch normalization. Comprehensive experiments on five healthcare benchmarks demonstrate that FedAP achieves better accuracy compared to state-of-the-art methods (e.g., 10%+ accuracy improvement for PAMAP2) with faster convergence speed.

## Justin D. Harris
https://www.microsoft.com/en-us/research/people/juharri/
Justin is using his experience in ML and crowdsourcing to implement a framework for ML in smart contracts to collect quality data and provide models that are free to use. Experiments are done on the Ethereum blockchain. Blog post: https://aka.ms/0xDeCA10B-blog1. Details: https://github.com/microsoft/0xDeCA10B. Justin is now interested in applying these incentives in a Federated Learning setting to ensure that while data is kept private, people can also be rewarded and fairly compensated for their contributions.

https://scholar.google.com/citations?user=w9QAUcAAAAAJ&hl=ko&oi=ao  
- https://www.microsoft.com/en-us/research/blog/leveraging-blockchain-to-make-machine-learning-models-more-accessible/
- Leveraging Blockchain for Greater Accessibility of Machine Learning Models, https://stanford-jblp.pubpub.org/pub/blockchain-machine-learning/release/1
- Blockchain-orchestrated machine learning for privacy preserving federated learning in electronic health data, https://scholar.google.com/citations?view_op=view_citation&hl=ko&user=w9QAUcAAAAAJ&sortby=pubdate&citft=1&citft=2&citft=3&email_for_op=KwangkeeLee%40gmail.com&citation_for_view=w9QAUcAAAAAJ:W7OEmFMy1HYC
- Decentralized & Collaborative AI on Blockchain, https://scholar.google.com/citations?view_op=view_citation&hl=ko&user=w9QAUcAAAAAJ&sortby=pubdate&citft=1&citft=2&citft=3&email_for_op=KwangkeeLee%40gmail.com&citation_for_view=w9QAUcAAAAAJ:9yKSN-GCB0IC
